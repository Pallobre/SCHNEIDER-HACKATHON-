{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2td5OM1GK1Lb",
        "outputId": "8736510f-6182-4344-e7e1-bd32b3ff2a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-1488bea2-0d4e-5df3-2a09-0919ecd83729)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "xLpRkumKRWpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras \n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import regularizers, optimizers\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "kng-ShsOK7zb"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOADING IMAGES\n"
      ],
      "metadata": {
        "id": "8RExcQjiRcKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_dir= \"/content/drive/MyDrive/schneider/train_test_data/train\"\n",
        "test_img_dir= \"/content/drive/MyDrive/schneider/train_test_data/test\"\n",
        "\n",
        "train_csv=\"/content/drive/MyDrive/schneider/train.csv\"\n",
        "test_csv=\"/content/drive/MyDrive/schneider/test.csv\"\n",
        "\n",
        "\n",
        "traindf=pd.read_csv(train_csv)\n",
        "testdf=pd.read_csv(test_csv)\n",
        "traindf[\"label\"]=traindf[\"label\"].apply(str)\n"
      ],
      "metadata": {
        "id": "9oomV4c4MD8y"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " DATA CLEANING"
      ],
      "metadata": {
        "id": "Vcc-DWZoxDvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nombrestrain(string):\n",
        "  return string[22:]\n",
        "def nombrestest(string):\n",
        "  return string[21:]\n",
        "\n",
        "traindf[\"id\"]= traindf[\"example_path\"].apply(nombrestrain)\n",
        "testdf[\"id\"]= testdf[\"example_path\"].apply(nombrestest)\n",
        "traindf = traindf[[\"id\", \"label\"]]\n",
        "testdf=testdf[[\"id\"]]"
      ],
      "metadata": {
        "id": "25zPsTwYPJuy"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CHECK if CLASSES are BALANCED  --> They are not"
      ],
      "metadata": {
        "id": "iM2o7HvmxNwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "traindf0 = traindf[traindf[\"label\"]==\"0\"].reset_index()[[\"id\", \"label\"]]\n",
        "traindf1 = traindf[traindf[\"label\"]==\"1\"].reset_index()[[\"id\", \"label\"]]\n",
        "traindf2 = traindf[traindf[\"label\"]==\"2\"].reset_index()[[\"id\", \"label\"]]\n",
        "\n",
        "print([len(traindf0), len(traindf1), len(traindf2)]) #CLASSES ARE UNBALANCED"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUP5sbHTbe4i",
        "outputId": "04f02a90-dd5b-4137-aadb-1f4deee7e39e"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[860, 196, 658]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BALANCING CLASES"
      ],
      "metadata": {
        "id": "c9cY0YJ9bfR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "balanceado0= traindf0\n",
        "balanceado1= traindf1.append(traindf1).append(traindf1).append(traindf1).append(traindf1[:76])\n",
        "balanceado2= traindf2.append(traindf2[:202])\n",
        "\n",
        "traindf= balanceado0.append(balanceado1).append(balanceado2).append(balanceado2)"
      ],
      "metadata": {
        "id": "iJRpPOaqQzWw"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[len(balanceado0),len(balanceado1),len(balanceado2)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2Bur0ujRMQb",
        "outputId": "73b72747-f8ee-4fa6-f43c-6a0fe4789f77"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[860, 860, 860]"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[len(traindf)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b_TpzKqZwdw",
        "outputId": "3a460810-03af-4922-c895-bd827c4fea9c"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3440]"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CROPPING FUNCTION for later..."
      ],
      "metadata": {
        "id": "L6LJ4Yl3xY7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rand_crop(img):\n",
        "    # Select size of crop\n",
        "    h = random.randint(input_size, image_size) \n",
        "    # Select lower left corner for crop\n",
        "    cx = random.randint(0, image_size-h)\n",
        "    cy = random.randint(0, image_size-h)\n",
        "    # Crop and resize image to input_size\n",
        "    cropped_img = img[cx:cx+h,cy:cy+h,:]\n",
        "    return cv2.resize(cropped_img, (input_size,input_size))\n"
      ],
      "metadata": {
        "id": "uen4YVz3S-Lf"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMAGE DATA GENERATOR"
      ],
      "metadata": {
        "id": "ZVdTy43exeQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.01) # I want all the data for the final prediction, just 34 images for validation because lack of time for fitting 2 models\n",
        "image_size = 1024\n",
        "input_size = 1024\n",
        "\n",
        "\n",
        "train_gen=datagen.flow_from_dataframe(\n",
        "dataframe=traindf, \n",
        "directory=train_img_dir, \n",
        "preprocessing_function = rand_crop,\n",
        "x_col=\"id\",\n",
        "y_col=\"label\",\n",
        "subset=\"training\",\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(32,32))\n",
        "\n",
        "\n",
        "valid_gen=datagen.flow_from_dataframe(\n",
        "dataframe=traindf,\n",
        "directory=train_img_dir,\n",
        "x_col=\"id\",\n",
        "y_col=\"label\",\n",
        "subset=\"validation\",\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "class_mode=\"categorical\",\n",
        "target_size=(32,32))\n",
        "\n",
        "\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=testdf,\n",
        "directory=test_img_dir,\n",
        "x_col=\"id\",\n",
        "y_col=None,\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=False,\n",
        "class_mode=None,\n",
        "target_size=(32,32))\n",
        "\n",
        "\n",
        "classes = dict((v, k) for k, v in train_gen.class_indices.items())\n",
        "num_classes = len(classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdMD95dDRVIK",
        "outputId": "5eaa8459-07d1-4e1e-ccd8-62569fa820be"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3406 validated image filenames belonging to 3 classes.\n",
            "Found 34 validated image filenames belonging to 3 classes.\n",
            "Found 286 validated image filenames.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 349 invalid image filename(s) in x_col=\"id\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGuKVMjGU6P0",
        "outputId": "007aaefe-df52-4a3d-94cc-1b8dd433419d"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NBe0g1l7U8BN"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING METRICS for the model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4kaMRsglU-ok"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGRy8lCPU8Dw"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "    \n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "        Only computes a batch-wise average of recall.\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "        Only computes a batch-wise average of precision.\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "  \n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "def precision(y_true, y_pred):\n",
        "    \"\"\"Precision metric.\n",
        "    Only computes a batch-wise average of precision.\n",
        "    Computes the precision, a metric for multi-label classification of\n",
        "    how many selected items are relevant.\n",
        "    \"\"\"\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "metadata": {
        "id": "bKv84h7CUVAo"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuVTVh2PVBU6"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WXBpiMnJVBac"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.layers import GlobalMaxPooling2D, Dense\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Create a VGG19 architecture\n",
        "pretrained_model = VGG19(include_top=False,\n",
        "                         \n",
        "                         input_shape=(input_size, input_size, 3),\n",
        "                         weights='imagenet')\n",
        "x = GlobalMaxPooling2D()(pretrained_model.output)\n",
        "\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "x = Dense(2048, activation='relu')(x)\n",
        "\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "vgg19_model = Model(pretrained_model.input, output)\n"
      ],
      "metadata": {
        "id": "_cdkVH8-UVTw"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create new model with modified config which accepts the input shape: [input_size, input_size, 1]\n",
        "cfg = vgg19_model.get_config()\n",
        "cfg['layers'][0]['config']['batch_input_shape'] = (None, input_size, input_size, 3)\n",
        "\n",
        "model = Model.from_config(cfg)\n",
        "\n",
        "for i, layer in enumerate(model.layers):\n",
        "    if i == 1:\n",
        "        layer.trainable = False\n",
        "    else:\n",
        "        layer.trainable = True \n",
        "        layer.set_weights(vgg19_model.layers[i].get_weights())\n",
        "\n",
        "# Compile the model with Adam optimizer, binary crossentropy loss and f1 score as the metric\n",
        "adam = Adam(lr=0.000005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False) # 10x smaller than standard\n",
        "model.compile(optimizer=adam, loss='binary_crossentropy', metrics=[f1])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atVJnyiUUVUr",
        "outputId": "39a66652-17ce-4583-fe10-853a1ab2d57a"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, 1024, 1024, 3)]   0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 1024, 1024, 64)    1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 1024, 1024, 64)    36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 512, 512, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 512, 512, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 512, 512, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 256, 256, 128)     0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 256, 256, 256)     295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 256, 256, 256)     590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 256, 256, 256)     590080    \n",
            "                                                                 \n",
            " block3_conv4 (Conv2D)       (None, 256, 256, 256)     590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 128, 128, 256)     0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 128, 128, 512)     1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 128, 128, 512)     2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 128, 128, 512)     2359808   \n",
            "                                                                 \n",
            " block4_conv4 (Conv2D)       (None, 128, 128, 512)     2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 64, 64, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv4 (Conv2D)       (None, 64, 64, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 32, 32, 512)       0         \n",
            "                                                                 \n",
            " global_max_pooling2d_8 (Glo  (None, 512)              0         \n",
            " balMaxPooling2D)                                                \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 2048)              1050624   \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 2048)              4196352   \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 3)                 6147      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,277,507\n",
            "Trainable params: 25,275,715\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TEST MODEL FOR SEEING F1 score with validation  Manually interrupted "
      ],
      "metadata": {
        "id": "7IrK1W66sEEu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit((train_gen),\n",
        "                              epochs=300,batch_size=20 ,\n",
        "                              steps_per_epoch=13, # Effectively 1 run through every possibility of reflected data\n",
        "                              validation_data=valid_gen,\n",
        "                              validation_steps=len(valid_gen))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98G7IyM-XN75",
        "outputId": "881107d4-400f-46dd-a4c0-7db8439fe172"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "13/13 [==============================] - 5s 271ms/step - loss: 0.6509 - f1: 0.0000e+00 - val_loss: 0.7423 - val_f1: 0.0000e+00\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5987 - f1: 0.4255 - val_loss: 0.8432 - val_f1: 0.0000e+00\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.6051 - f1: 0.5096 - val_loss: 0.8431 - val_f1: 0.0000e+00\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.6202 - f1: 0.4663 - val_loss: 0.7746 - val_f1: 0.0000e+00\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.6063 - f1: 0.5072 - val_loss: 0.7948 - val_f1: 0.0000e+00\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5995 - f1: 0.5168 - val_loss: 0.8252 - val_f1: 0.0000e+00\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.6131 - f1: 0.4808 - val_loss: 0.8516 - val_f1: 0.0000e+00\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.5976 - f1: 0.5240 - val_loss: 0.8155 - val_f1: 0.0000e+00\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5993 - f1: 0.5192 - val_loss: 0.8188 - val_f1: 0.0000e+00\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 3s 217ms/step - loss: 0.6201 - f1: 0.4725 - val_loss: 0.7755 - val_f1: 0.0000e+00\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.6108 - f1: 0.4904 - val_loss: 0.7375 - val_f1: 0.0000e+00\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5974 - f1: 0.5288 - val_loss: 0.8052 - val_f1: 0.0000e+00\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5993 - f1: 0.5168 - val_loss: 0.7792 - val_f1: 0.0000e+00\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.6142 - f1: 0.4808 - val_loss: 0.7924 - val_f1: 0.0000e+00\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5891 - f1: 0.5457 - val_loss: 0.7946 - val_f1: 0.0000e+00\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.6052 - f1: 0.5024 - val_loss: 0.7769 - val_f1: 0.0000e+00\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.6071 - f1: 0.5000 - val_loss: 0.7860 - val_f1: 0.0000e+00\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5989 - f1: 0.5168 - val_loss: 0.8511 - val_f1: 0.0000e+00\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.6125 - f1: 0.4784 - val_loss: 0.8187 - val_f1: 0.0000e+00\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.6088 - f1: 0.4880 - val_loss: 0.7847 - val_f1: 0.0000e+00\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.6036 - f1: 0.5024 - val_loss: 0.7838 - val_f1: 0.0000e+00\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.6008 - f1: 0.5120 - val_loss: 0.7650 - val_f1: 0.0000e+00\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.6016 - f1: 0.5010 - val_loss: 0.7670 - val_f1: 0.0000e+00\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.6001 - f1: 0.5192 - val_loss: 0.8257 - val_f1: 0.0000e+00\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.6057 - f1: 0.4952 - val_loss: 0.7372 - val_f1: 0.0000e+00\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 0.6053 - f1: 0.4921 - val_loss: 0.7736 - val_f1: 0.0000e+00\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.6121 - f1: 0.4760 - val_loss: 0.7713 - val_f1: 0.0000e+00\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5944 - f1: 0.5240 - val_loss: 0.7788 - val_f1: 0.0000e+00\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5980 - f1: 0.5192 - val_loss: 0.8180 - val_f1: 0.0000e+00\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5987 - f1: 0.5192 - val_loss: 0.7501 - val_f1: 0.0000e+00\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.6035 - f1: 0.5096 - val_loss: 0.8171 - val_f1: 0.0000e+00\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 3s 219ms/step - loss: 0.6154 - f1: 0.4615 - val_loss: 0.7704 - val_f1: 0.0000e+00\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.6079 - f1: 0.4880 - val_loss: 0.7002 - val_f1: 0.0000e+00\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.6012 - f1: 0.5000 - val_loss: 0.7935 - val_f1: 0.0000e+00\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.6081 - f1: 0.4904 - val_loss: 0.7793 - val_f1: 0.0000e+00\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5949 - f1: 0.5144 - val_loss: 0.8003 - val_f1: 0.0000e+00\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.6101 - f1: 0.4736 - val_loss: 0.7392 - val_f1: 0.0000e+00\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.6069 - f1: 0.4904 - val_loss: 0.7544 - val_f1: 0.0000e+00\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5835 - f1: 0.5529 - val_loss: 0.8421 - val_f1: 0.0000e+00\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5983 - f1: 0.5096 - val_loss: 0.8013 - val_f1: 0.0000e+00\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.6000 - f1: 0.4928 - val_loss: 0.8010 - val_f1: 0.0000e+00\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.6055 - f1: 0.4808 - val_loss: 0.7040 - val_f1: 0.0000e+00\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5966 - f1: 0.5048 - val_loss: 0.7464 - val_f1: 0.0000e+00\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.6061 - f1: 0.4928 - val_loss: 0.7915 - val_f1: 0.0000e+00\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5932 - f1: 0.5216 - val_loss: 0.8038 - val_f1: 0.0000e+00\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.6074 - f1: 0.4639 - val_loss: 0.7630 - val_f1: 0.0000e+00\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5926 - f1: 0.5337 - val_loss: 0.7809 - val_f1: 0.0000e+00\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5845 - f1: 0.5361 - val_loss: 0.8586 - val_f1: 0.0000e+00\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5896 - f1: 0.5192 - val_loss: 0.7681 - val_f1: 0.0000e+00\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 3s 217ms/step - loss: 0.5955 - f1: 0.5179 - val_loss: 0.7665 - val_f1: 0.0000e+00\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.6001 - f1: 0.4952 - val_loss: 0.7814 - val_f1: 0.0000e+00\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.6134 - f1: 0.4543 - val_loss: 0.7048 - val_f1: 0.0000e+00\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5893 - f1: 0.5246 - val_loss: 0.7764 - val_f1: 0.0000e+00\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5928 - f1: 0.4928 - val_loss: 0.7269 - val_f1: 0.0000e+00\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.5943 - f1: 0.4605 - val_loss: 0.6249 - val_f1: 0.0000e+00\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.5895 - f1: 0.5107 - val_loss: 0.6872 - val_f1: 0.0000e+00\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5871 - f1: 0.5055 - val_loss: 0.8227 - val_f1: 0.0000e+00\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5775 - f1: 0.5079 - val_loss: 0.7584 - val_f1: 0.0000e+00\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5840 - f1: 0.4943 - val_loss: 0.6479 - val_f1: 0.0000e+00\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5781 - f1: 0.5056 - val_loss: 0.8153 - val_f1: 0.0000e+00\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.6099 - f1: 0.4608 - val_loss: 0.6519 - val_f1: 0.2500\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5981 - f1: 0.4916 - val_loss: 0.6690 - val_f1: 0.0000e+00\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5951 - f1: 0.4695 - val_loss: 0.8228 - val_f1: 0.0000e+00\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5930 - f1: 0.5108 - val_loss: 0.7372 - val_f1: 0.0000e+00\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5999 - f1: 0.4693 - val_loss: 0.6731 - val_f1: 0.0000e+00\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5969 - f1: 0.4449 - val_loss: 0.7270 - val_f1: 0.0000e+00\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.5758 - f1: 0.4955 - val_loss: 0.8171 - val_f1: 0.0000e+00\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5705 - f1: 0.5369 - val_loss: 0.5734 - val_f1: 0.4956\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5878 - f1: 0.4610 - val_loss: 0.6147 - val_f1: 0.2182\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5533 - f1: 0.5683 - val_loss: 0.7139 - val_f1: 0.0328\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5732 - f1: 0.5053 - val_loss: 0.5718 - val_f1: 0.5167\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5700 - f1: 0.5150 - val_loss: 0.6487 - val_f1: 0.1475\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5627 - f1: 0.5208 - val_loss: 0.7219 - val_f1: 0.0893\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5604 - f1: 0.5355 - val_loss: 0.7758 - val_f1: 0.2656\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 3s 229ms/step - loss: 0.5727 - f1: 0.4830 - val_loss: 0.7147 - val_f1: 0.2685\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.5445 - f1: 0.5441 - val_loss: 0.9561 - val_f1: 0.0000e+00\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 3s 215ms/step - loss: 0.5451 - f1: 0.5558 - val_loss: 0.7695 - val_f1: 0.0339\n",
            "Epoch 78/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5689 - f1: 0.5569 - val_loss: 0.9872 - val_f1: 0.0000e+00\n",
            "Epoch 79/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5825 - f1: 0.4546 - val_loss: 0.6100 - val_f1: 0.6667\n",
            "Epoch 80/300\n",
            "13/13 [==============================] - 3s 215ms/step - loss: 0.5666 - f1: 0.5238 - val_loss: 0.8160 - val_f1: 0.0000e+00\n",
            "Epoch 81/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5458 - f1: 0.5535 - val_loss: 0.7273 - val_f1: 0.0492\n",
            "Epoch 82/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5539 - f1: 0.5338 - val_loss: 0.6120 - val_f1: 0.4919\n",
            "Epoch 83/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5689 - f1: 0.5070 - val_loss: 0.6666 - val_f1: 0.3750\n",
            "Epoch 84/300\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 0.5754 - f1: 0.5314 - val_loss: 0.7884 - val_f1: 0.0175\n",
            "Epoch 85/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5554 - f1: 0.5419 - val_loss: 0.8060 - val_f1: 0.0323\n",
            "Epoch 86/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5430 - f1: 0.5847 - val_loss: 0.7881 - val_f1: 0.0508\n",
            "Epoch 87/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5568 - f1: 0.5571 - val_loss: 0.6351 - val_f1: 0.2295\n",
            "Epoch 88/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5624 - f1: 0.4962 - val_loss: 0.7643 - val_f1: 0.0952\n",
            "Epoch 89/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5456 - f1: 0.5546 - val_loss: 0.8437 - val_f1: 0.0323\n",
            "Epoch 90/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.5767 - f1: 0.4902 - val_loss: 0.8300 - val_f1: 0.0364\n",
            "Epoch 91/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5689 - f1: 0.5223 - val_loss: 0.6398 - val_f1: 0.4534\n",
            "Epoch 92/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5594 - f1: 0.5340 - val_loss: 0.8319 - val_f1: 0.0312\n",
            "Epoch 93/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5718 - f1: 0.5114 - val_loss: 0.8450 - val_f1: 0.0169\n",
            "Epoch 94/300\n",
            "13/13 [==============================] - 3s 228ms/step - loss: 0.5845 - f1: 0.4876 - val_loss: 0.7324 - val_f1: 0.0377\n",
            "Epoch 95/300\n",
            "13/13 [==============================] - 3s 217ms/step - loss: 0.5585 - f1: 0.5458 - val_loss: 0.8062 - val_f1: 0.0161\n",
            "Epoch 96/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5460 - f1: 0.5423 - val_loss: 0.5443 - val_f1: 0.3051\n",
            "Epoch 97/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5624 - f1: 0.5424 - val_loss: 0.9370 - val_f1: 0.0000e+00\n",
            "Epoch 98/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5570 - f1: 0.5076 - val_loss: 0.6793 - val_f1: 0.4762\n",
            "Epoch 99/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5486 - f1: 0.5454 - val_loss: 0.8708 - val_f1: 0.0312\n",
            "Epoch 100/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5646 - f1: 0.5438 - val_loss: 0.7480 - val_f1: 0.0323\n",
            "Epoch 101/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5701 - f1: 0.5410 - val_loss: 0.6655 - val_f1: 0.3393\n",
            "Epoch 102/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5475 - f1: 0.5422 - val_loss: 0.7839 - val_f1: 0.0159\n",
            "Epoch 103/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5387 - f1: 0.5770 - val_loss: 0.5836 - val_f1: 0.2459\n",
            "Epoch 104/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5445 - f1: 0.5494 - val_loss: 0.6903 - val_f1: 0.1186\n",
            "Epoch 105/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5357 - f1: 0.5857 - val_loss: 0.5849 - val_f1: 0.7258\n",
            "Epoch 106/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5621 - f1: 0.5536 - val_loss: 0.6140 - val_f1: 0.4667\n",
            "Epoch 107/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5490 - f1: 0.5557 - val_loss: 0.7815 - val_f1: 0.4444\n",
            "Epoch 108/300\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 0.5620 - f1: 0.5338 - val_loss: 0.7228 - val_f1: 0.1273\n",
            "Epoch 109/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5290 - f1: 0.6030 - val_loss: 0.7953 - val_f1: 0.0323\n",
            "Epoch 110/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5427 - f1: 0.5617 - val_loss: 0.7435 - val_f1: 0.0862\n",
            "Epoch 111/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5489 - f1: 0.5802 - val_loss: 0.8058 - val_f1: 0.0364\n",
            "Epoch 112/300\n",
            "13/13 [==============================] - 3s 219ms/step - loss: 0.5412 - f1: 0.5481 - val_loss: 0.7926 - val_f1: 0.0385\n",
            "Epoch 113/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5240 - f1: 0.6073 - val_loss: 0.6347 - val_f1: 0.2281\n",
            "Epoch 114/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5548 - f1: 0.5355 - val_loss: 0.7191 - val_f1: 0.3347\n",
            "Epoch 115/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5511 - f1: 0.5500 - val_loss: 0.8746 - val_f1: 0.0182\n",
            "Epoch 116/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5251 - f1: 0.5849 - val_loss: 0.6567 - val_f1: 0.4274\n",
            "Epoch 117/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5368 - f1: 0.5791 - val_loss: 0.6602 - val_f1: 0.4318\n",
            "Epoch 118/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5303 - f1: 0.5789 - val_loss: 0.6318 - val_f1: 0.4631\n",
            "Epoch 119/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.5320 - f1: 0.5766 - val_loss: 0.8356 - val_f1: 0.0323\n",
            "Epoch 120/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5446 - f1: 0.5900 - val_loss: 0.8423 - val_f1: 0.0345\n",
            "Epoch 121/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5648 - f1: 0.5216 - val_loss: 0.5335 - val_f1: 0.2982\n",
            "Epoch 122/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5352 - f1: 0.5767 - val_loss: 0.6614 - val_f1: 0.4375\n",
            "Epoch 123/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5440 - f1: 0.5765 - val_loss: 0.6103 - val_f1: 0.5301\n",
            "Epoch 124/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5223 - f1: 0.5966 - val_loss: 0.8619 - val_f1: 0.0323\n",
            "Epoch 125/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5354 - f1: 0.5504 - val_loss: 0.7353 - val_f1: 0.3362\n",
            "Epoch 126/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5443 - f1: 0.5532 - val_loss: 0.6935 - val_f1: 0.1754\n",
            "Epoch 127/300\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 0.5257 - f1: 0.6001 - val_loss: 0.8113 - val_f1: 0.0328\n",
            "Epoch 128/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5193 - f1: 0.5889 - val_loss: 0.8197 - val_f1: 0.0345\n",
            "Epoch 129/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5367 - f1: 0.5692 - val_loss: 0.7025 - val_f1: 0.1695\n",
            "Epoch 130/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5599 - f1: 0.5247 - val_loss: 0.5798 - val_f1: 0.7264\n",
            "Epoch 131/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5355 - f1: 0.5570 - val_loss: 0.6968 - val_f1: 0.4333\n",
            "Epoch 132/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5236 - f1: 0.5879 - val_loss: 0.7471 - val_f1: 0.1148\n",
            "Epoch 133/300\n",
            "13/13 [==============================] - 3s 211ms/step - loss: 0.5099 - f1: 0.5914 - val_loss: 0.6725 - val_f1: 0.2097\n",
            "Epoch 134/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5335 - f1: 0.5534 - val_loss: 0.6088 - val_f1: 0.4667\n",
            "Epoch 135/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5356 - f1: 0.5564 - val_loss: 0.6711 - val_f1: 0.6404\n",
            "Epoch 136/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5112 - f1: 0.6145 - val_loss: 0.8847 - val_f1: 0.0328\n",
            "Epoch 137/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5385 - f1: 0.5692 - val_loss: 0.6937 - val_f1: 0.4667\n",
            "Epoch 138/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5257 - f1: 0.5863 - val_loss: 0.6741 - val_f1: 0.6774\n",
            "Epoch 139/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5207 - f1: 0.5662 - val_loss: 0.5844 - val_f1: 0.2586\n",
            "Epoch 140/300\n",
            "13/13 [==============================] - 3s 214ms/step - loss: 0.5226 - f1: 0.5608 - val_loss: 0.7460 - val_f1: 0.3534\n",
            "Epoch 141/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5247 - f1: 0.5723 - val_loss: 0.6671 - val_f1: 0.1176\n",
            "Epoch 142/300\n",
            "13/13 [==============================] - 3s 216ms/step - loss: 0.5188 - f1: 0.5764 - val_loss: 0.6889 - val_f1: 0.1579\n",
            "Epoch 143/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5048 - f1: 0.6006 - val_loss: 0.9383 - val_f1: 0.0156\n",
            "Epoch 144/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.5530 - f1: 0.5071 - val_loss: 0.7380 - val_f1: 0.3517\n",
            "Epoch 145/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5144 - f1: 0.6170 - val_loss: 0.8878 - val_f1: 0.2669\n",
            "Epoch 146/300\n",
            "13/13 [==============================] - 3s 214ms/step - loss: 0.4972 - f1: 0.6248 - val_loss: 0.6880 - val_f1: 0.1296\n",
            "Epoch 147/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5119 - f1: 0.6006 - val_loss: 0.7156 - val_f1: 0.3571\n",
            "Epoch 148/300\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 0.5152 - f1: 0.5944 - val_loss: 0.6926 - val_f1: 0.3952\n",
            "Epoch 149/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.5365 - f1: 0.5376 - val_loss: 0.7507 - val_f1: 0.0794\n",
            "Epoch 150/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4884 - f1: 0.6374 - val_loss: 0.6402 - val_f1: 0.4682\n",
            "Epoch 151/300\n",
            "13/13 [==============================] - 3s 212ms/step - loss: 0.4949 - f1: 0.6239 - val_loss: 0.6859 - val_f1: 0.1833\n",
            "Epoch 152/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4992 - f1: 0.6102 - val_loss: 0.6899 - val_f1: 0.3571\n",
            "Epoch 153/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5351 - f1: 0.5390 - val_loss: 0.6996 - val_f1: 0.4737\n",
            "Epoch 154/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5354 - f1: 0.5499 - val_loss: 0.7714 - val_f1: 0.2851\n",
            "Epoch 155/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4949 - f1: 0.6177 - val_loss: 0.7428 - val_f1: 0.3517\n",
            "Epoch 156/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5351 - f1: 0.5780 - val_loss: 0.5732 - val_f1: 0.2931\n",
            "Epoch 157/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.4945 - f1: 0.6098 - val_loss: 0.6866 - val_f1: 0.1667\n",
            "Epoch 158/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4905 - f1: 0.6334 - val_loss: 0.6791 - val_f1: 0.4424\n",
            "Epoch 159/300\n",
            "13/13 [==============================] - 3s 215ms/step - loss: 0.4937 - f1: 0.6183 - val_loss: 0.8094 - val_f1: 0.1148\n",
            "Epoch 160/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5015 - f1: 0.6057 - val_loss: 0.7047 - val_f1: 0.4167\n",
            "Epoch 161/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5073 - f1: 0.5962 - val_loss: 0.5233 - val_f1: 0.7881\n",
            "Epoch 162/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.5063 - f1: 0.5954 - val_loss: 0.6561 - val_f1: 0.6429\n",
            "Epoch 163/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.4772 - f1: 0.6170 - val_loss: 0.5759 - val_f1: 0.7222\n",
            "Epoch 164/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.4799 - f1: 0.6188 - val_loss: 0.8894 - val_f1: 0.0820\n",
            "Epoch 165/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.5252 - f1: 0.6162 - val_loss: 0.7040 - val_f1: 0.1481\n",
            "Epoch 166/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5143 - f1: 0.6016 - val_loss: 0.6286 - val_f1: 0.5333\n",
            "Epoch 167/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4923 - f1: 0.6042 - val_loss: 0.6253 - val_f1: 0.2105\n",
            "Epoch 168/300\n",
            "13/13 [==============================] - 3s 219ms/step - loss: 0.4749 - f1: 0.6456 - val_loss: 0.7435 - val_f1: 0.4540\n",
            "Epoch 169/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4901 - f1: 0.5922 - val_loss: 0.7079 - val_f1: 0.1754\n",
            "Epoch 170/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4797 - f1: 0.6104 - val_loss: 0.6393 - val_f1: 0.4682\n",
            "Epoch 171/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4682 - f1: 0.6581 - val_loss: 0.7652 - val_f1: 0.1000\n",
            "Epoch 172/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4725 - f1: 0.6315 - val_loss: 0.6566 - val_f1: 0.5430\n",
            "Epoch 173/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4522 - f1: 0.6568 - val_loss: 0.5302 - val_f1: 0.5381\n",
            "Epoch 174/300\n",
            "13/13 [==============================] - 3s 215ms/step - loss: 0.4911 - f1: 0.6260 - val_loss: 0.5672 - val_f1: 0.3115\n",
            "Epoch 175/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.4911 - f1: 0.6153 - val_loss: 0.8220 - val_f1: 0.3707\n",
            "Epoch 176/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.4820 - f1: 0.6464 - val_loss: 0.8906 - val_f1: 0.4127\n",
            "Epoch 177/300\n",
            "13/13 [==============================] - 3s 212ms/step - loss: 0.4630 - f1: 0.6713 - val_loss: 0.8334 - val_f1: 0.1148\n",
            "Epoch 178/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5125 - f1: 0.5606 - val_loss: 0.7087 - val_f1: 0.1724\n",
            "Epoch 179/300\n",
            "13/13 [==============================] - 3s 215ms/step - loss: 0.5025 - f1: 0.5974 - val_loss: 0.7287 - val_f1: 0.1429\n",
            "Epoch 180/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.5049 - f1: 0.5979 - val_loss: 0.8087 - val_f1: 0.1000\n",
            "Epoch 181/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.4847 - f1: 0.6404 - val_loss: 0.7463 - val_f1: 0.1186\n",
            "Epoch 182/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.4748 - f1: 0.6561 - val_loss: 0.7417 - val_f1: 0.5984\n",
            "Epoch 183/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.4818 - f1: 0.6360 - val_loss: 0.7586 - val_f1: 0.0984\n",
            "Epoch 184/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.4603 - f1: 0.6421 - val_loss: 0.6171 - val_f1: 0.5833\n",
            "Epoch 185/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4488 - f1: 0.6797 - val_loss: 0.6321 - val_f1: 0.4195\n",
            "Epoch 186/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4752 - f1: 0.6397 - val_loss: 0.8115 - val_f1: 0.4167\n",
            "Epoch 187/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4743 - f1: 0.6505 - val_loss: 0.8144 - val_f1: 0.3484\n",
            "Epoch 188/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.4894 - f1: 0.6175 - val_loss: 0.7257 - val_f1: 0.1167\n",
            "Epoch 189/300\n",
            "13/13 [==============================] - 3s 214ms/step - loss: 0.4867 - f1: 0.6217 - val_loss: 0.7667 - val_f1: 0.3790\n",
            "Epoch 190/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.4671 - f1: 0.6441 - val_loss: 0.6100 - val_f1: 0.4467\n",
            "Epoch 191/300\n",
            "13/13 [==============================] - 3s 214ms/step - loss: 0.4928 - f1: 0.6154 - val_loss: 0.6266 - val_f1: 0.1833\n",
            "Epoch 192/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4619 - f1: 0.6459 - val_loss: 0.5734 - val_f1: 0.2295\n",
            "Epoch 193/300\n",
            "13/13 [==============================] - 3s 230ms/step - loss: 0.4735 - f1: 0.6364 - val_loss: 0.7819 - val_f1: 0.4286\n",
            "Epoch 194/300\n",
            "13/13 [==============================] - 3s 236ms/step - loss: 0.4775 - f1: 0.6161 - val_loss: 0.8348 - val_f1: 0.3347\n",
            "Epoch 195/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.5228 - f1: 0.6082 - val_loss: 0.8132 - val_f1: 0.2845\n",
            "Epoch 196/300\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.4656 - f1: 0.6547 - val_loss: 0.6570 - val_f1: 0.2373\n",
            "Epoch 197/300\n",
            "13/13 [==============================] - 3s 214ms/step - loss: 0.4455 - f1: 0.6681 - val_loss: 0.6289 - val_f1: 0.6967\n",
            "Epoch 198/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4602 - f1: 0.6622 - val_loss: 0.6347 - val_f1: 0.7258\n",
            "Epoch 199/300\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.4549 - f1: 0.6482 - val_loss: 0.6616 - val_f1: 0.4795\n",
            "Epoch 200/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.4706 - f1: 0.6551 - val_loss: 0.8310 - val_f1: 0.5820\n",
            "Epoch 201/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.4863 - f1: 0.6245 - val_loss: 0.8047 - val_f1: 0.1167\n",
            "Epoch 202/300\n",
            "13/13 [==============================] - 3s 230ms/step - loss: 0.4452 - f1: 0.6776 - val_loss: 0.5016 - val_f1: 0.7903\n",
            "Epoch 203/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.4507 - f1: 0.6794 - val_loss: 0.6428 - val_f1: 0.2258\n",
            "Epoch 204/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4455 - f1: 0.6804 - val_loss: 0.7517 - val_f1: 0.1552\n",
            "Epoch 205/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4437 - f1: 0.6615 - val_loss: 0.7397 - val_f1: 0.4219\n",
            "Epoch 206/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.4583 - f1: 0.6593 - val_loss: 0.8370 - val_f1: 0.1167\n",
            "Epoch 207/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4402 - f1: 0.6718 - val_loss: 1.0012 - val_f1: 0.0781\n",
            "Epoch 208/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4350 - f1: 0.6871 - val_loss: 1.0448 - val_f1: 0.0317\n",
            "Epoch 209/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.4664 - f1: 0.6444 - val_loss: 0.5857 - val_f1: 0.5287\n",
            "Epoch 210/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.4392 - f1: 0.6777 - val_loss: 0.6132 - val_f1: 0.5042\n",
            "Epoch 211/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.4807 - f1: 0.6274 - val_loss: 0.4749 - val_f1: 0.8333\n",
            "Epoch 212/300\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.4509 - f1: 0.6840 - val_loss: 0.7373 - val_f1: 0.4000\n",
            "Epoch 213/300\n",
            "13/13 [==============================] - 3s 227ms/step - loss: 0.4412 - f1: 0.6732 - val_loss: 0.8002 - val_f1: 0.4481\n",
            "Epoch 214/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4667 - f1: 0.6374 - val_loss: 0.9458 - val_f1: 0.0345\n",
            "Epoch 215/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.4428 - f1: 0.6982 - val_loss: 0.8467 - val_f1: 0.1000\n",
            "Epoch 216/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4376 - f1: 0.6995 - val_loss: 0.8350 - val_f1: 0.3629\n",
            "Epoch 217/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4336 - f1: 0.6941 - val_loss: 0.5543 - val_f1: 0.2857\n",
            "Epoch 218/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4277 - f1: 0.7140 - val_loss: 0.7220 - val_f1: 0.4597\n",
            "Epoch 219/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4205 - f1: 0.6685 - val_loss: 0.7296 - val_f1: 0.2131\n",
            "Epoch 220/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4380 - f1: 0.6593 - val_loss: 0.7631 - val_f1: 0.4500\n",
            "Epoch 221/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.3830 - f1: 0.7367 - val_loss: 0.6914 - val_f1: 0.2787\n",
            "Epoch 222/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4396 - f1: 0.6864 - val_loss: 0.5143 - val_f1: 0.7969\n",
            "Epoch 223/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4684 - f1: 0.6471 - val_loss: 0.5318 - val_f1: 0.5565\n",
            "Epoch 224/300\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 0.4319 - f1: 0.6766 - val_loss: 0.7184 - val_f1: 0.4303\n",
            "Epoch 225/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4308 - f1: 0.6852 - val_loss: 0.8693 - val_f1: 0.1311\n",
            "Epoch 226/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4283 - f1: 0.6746 - val_loss: 0.6234 - val_f1: 0.2581\n",
            "Epoch 227/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.3692 - f1: 0.7658 - val_loss: 0.7096 - val_f1: 0.5269\n",
            "Epoch 228/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4327 - f1: 0.6848 - val_loss: 0.7306 - val_f1: 0.2459\n",
            "Epoch 229/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4072 - f1: 0.6921 - val_loss: 0.7052 - val_f1: 0.2500\n",
            "Epoch 230/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.4432 - f1: 0.6687 - val_loss: 0.5657 - val_f1: 0.3333\n",
            "Epoch 231/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4243 - f1: 0.6927 - val_loss: 0.9120 - val_f1: 0.1186\n",
            "Epoch 232/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3949 - f1: 0.7230 - val_loss: 0.8370 - val_f1: 0.4139\n",
            "Epoch 233/300\n",
            "13/13 [==============================] - 3s 214ms/step - loss: 0.4455 - f1: 0.6675 - val_loss: 0.9111 - val_f1: 0.1167\n",
            "Epoch 234/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3739 - f1: 0.7399 - val_loss: 0.6943 - val_f1: 0.4435\n",
            "Epoch 235/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.4691 - f1: 0.6224 - val_loss: 0.5639 - val_f1: 0.3051\n",
            "Epoch 236/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4267 - f1: 0.6903 - val_loss: 0.6616 - val_f1: 0.2258\n",
            "Epoch 237/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4215 - f1: 0.6753 - val_loss: 0.7939 - val_f1: 0.1639\n",
            "Epoch 238/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4488 - f1: 0.6611 - val_loss: 0.6730 - val_f1: 0.2456\n",
            "Epoch 239/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.3922 - f1: 0.7342 - val_loss: 0.8269 - val_f1: 0.4603\n",
            "Epoch 240/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.4470 - f1: 0.6582 - val_loss: 0.7109 - val_f1: 0.4167\n",
            "Epoch 241/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4326 - f1: 0.6797 - val_loss: 0.6860 - val_f1: 0.2167\n",
            "Epoch 242/300\n",
            "13/13 [==============================] - 3s 212ms/step - loss: 0.3837 - f1: 0.7456 - val_loss: 0.6326 - val_f1: 0.2656\n",
            "Epoch 243/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3842 - f1: 0.7584 - val_loss: 0.7587 - val_f1: 0.6935\n",
            "Epoch 244/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4184 - f1: 0.6829 - val_loss: 0.5932 - val_f1: 0.5156\n",
            "Epoch 245/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.4288 - f1: 0.6908 - val_loss: 0.7639 - val_f1: 0.1803\n",
            "Epoch 246/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3964 - f1: 0.7254 - val_loss: 0.9178 - val_f1: 0.6186\n",
            "Epoch 247/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3836 - f1: 0.7389 - val_loss: 0.6639 - val_f1: 0.7698\n",
            "Epoch 248/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.3990 - f1: 0.7152 - val_loss: 0.7618 - val_f1: 0.7373\n",
            "Epoch 249/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4559 - f1: 0.6495 - val_loss: 0.7210 - val_f1: 0.4405\n",
            "Epoch 250/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4071 - f1: 0.7205 - val_loss: 0.6712 - val_f1: 0.4631\n",
            "Epoch 251/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.3710 - f1: 0.7394 - val_loss: 0.6175 - val_f1: 0.7344\n",
            "Epoch 252/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4054 - f1: 0.7180 - val_loss: 1.0140 - val_f1: 0.3500\n",
            "Epoch 253/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4999 - f1: 0.6215 - val_loss: 1.0653 - val_f1: 0.0000e+00\n",
            "Epoch 254/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4090 - f1: 0.6991 - val_loss: 0.6463 - val_f1: 0.4631\n",
            "Epoch 255/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.3718 - f1: 0.7504 - val_loss: 0.5634 - val_f1: 0.7742\n",
            "Epoch 256/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.4566 - f1: 0.6581 - val_loss: 0.6050 - val_f1: 0.5381\n",
            "Epoch 257/300\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.4136 - f1: 0.7082 - val_loss: 0.7455 - val_f1: 0.6667\n",
            "Epoch 258/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3960 - f1: 0.7184 - val_loss: 0.7771 - val_f1: 0.3952\n",
            "Epoch 259/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3748 - f1: 0.7570 - val_loss: 0.8026 - val_f1: 0.1803\n",
            "Epoch 260/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.3863 - f1: 0.7230 - val_loss: 0.8507 - val_f1: 0.4025\n",
            "Epoch 261/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3652 - f1: 0.7695 - val_loss: 0.7251 - val_f1: 0.2500\n",
            "Epoch 262/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3789 - f1: 0.7594 - val_loss: 0.7413 - val_f1: 0.7500\n",
            "Epoch 263/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.3745 - f1: 0.7528 - val_loss: 0.6597 - val_f1: 0.5000\n",
            "Epoch 264/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.4180 - f1: 0.7119 - val_loss: 0.7245 - val_f1: 0.7063\n",
            "Epoch 265/300\n",
            "13/13 [==============================] - 3s 228ms/step - loss: 0.3939 - f1: 0.7177 - val_loss: 0.7801 - val_f1: 0.4914\n",
            "Epoch 266/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3626 - f1: 0.7609 - val_loss: 0.6253 - val_f1: 0.7742\n",
            "Epoch 267/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.3837 - f1: 0.7259 - val_loss: 0.6507 - val_f1: 0.2903\n",
            "Epoch 268/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3815 - f1: 0.7106 - val_loss: 0.5102 - val_f1: 0.5469\n",
            "Epoch 269/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4236 - f1: 0.6762 - val_loss: 0.6788 - val_f1: 0.4722\n",
            "Epoch 270/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.3741 - f1: 0.7414 - val_loss: 0.7565 - val_f1: 0.4833\n",
            "Epoch 271/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.3634 - f1: 0.7883 - val_loss: 0.7426 - val_f1: 0.2381\n",
            "Epoch 272/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.4168 - f1: 0.6935 - val_loss: 0.6339 - val_f1: 0.5081\n",
            "Epoch 273/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.3966 - f1: 0.7359 - val_loss: 0.5609 - val_f1: 0.5242\n",
            "Epoch 274/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3629 - f1: 0.7461 - val_loss: 0.9627 - val_f1: 0.0968\n",
            "Epoch 275/300\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 0.3686 - f1: 0.7453 - val_loss: 1.1865 - val_f1: 0.0635\n",
            "Epoch 276/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.4043 - f1: 0.7010 - val_loss: 0.7607 - val_f1: 0.4435\n",
            "Epoch 277/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3719 - f1: 0.7386 - val_loss: 0.6863 - val_f1: 0.2742\n",
            "Epoch 278/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.3303 - f1: 0.7974 - val_loss: 0.6779 - val_f1: 0.7344\n",
            "Epoch 279/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.3464 - f1: 0.7740 - val_loss: 0.8763 - val_f1: 0.4303\n",
            "Epoch 280/300\n",
            "13/13 [==============================] - 3s 221ms/step - loss: 0.3715 - f1: 0.7374 - val_loss: 0.5876 - val_f1: 0.2742\n",
            "Epoch 281/300\n",
            "13/13 [==============================] - 3s 224ms/step - loss: 0.3664 - f1: 0.7557 - val_loss: 0.7906 - val_f1: 0.2258\n",
            "Epoch 282/300\n",
            "13/13 [==============================] - 3s 220ms/step - loss: 0.3670 - f1: 0.7510 - val_loss: 0.9052 - val_f1: 0.1406\n",
            "Epoch 283/300\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 0.3961 - f1: 0.7274 - val_loss: 0.6999 - val_f1: 0.7459\n",
            "Epoch 284/300\n",
            "13/13 [==============================] - 3s 213ms/step - loss: 0.3649 - f1: 0.7380 - val_loss: 0.6587 - val_f1: 0.4758\n",
            "Epoch 285/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3395 - f1: 0.7765 - val_loss: 0.7161 - val_f1: 0.7222\n",
            "Epoch 286/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.3439 - f1: 0.7889 - val_loss: 0.8448 - val_f1: 0.4500\n",
            "Epoch 287/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.3210 - f1: 0.7921 - val_loss: 0.8404 - val_f1: 0.6746\n",
            "Epoch 288/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.3575 - f1: 0.7664 - val_loss: 0.7638 - val_f1: 0.2540\n",
            "Epoch 289/300\n",
            "13/13 [==============================] - 3s 231ms/step - loss: 0.3283 - f1: 0.7912 - val_loss: 0.8476 - val_f1: 0.4274\n",
            "Epoch 290/300\n",
            "13/13 [==============================] - 3s 229ms/step - loss: 0.3660 - f1: 0.7229 - val_loss: 0.9121 - val_f1: 0.4274\n",
            "Epoch 291/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.3198 - f1: 0.7996 - val_loss: 0.6807 - val_f1: 0.5000\n",
            "Epoch 292/300\n",
            "13/13 [==============================] - 3s 226ms/step - loss: 0.3377 - f1: 0.7864 - val_loss: 0.7906 - val_f1: 0.4531\n",
            "Epoch 293/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3608 - f1: 0.7382 - val_loss: 1.0046 - val_f1: 0.1746\n",
            "Epoch 294/300\n",
            "13/13 [==============================] - 3s 222ms/step - loss: 0.3379 - f1: 0.7739 - val_loss: 0.7017 - val_f1: 0.7540\n",
            "Epoch 295/300\n",
            "13/13 [==============================] - 3s 230ms/step - loss: 0.3550 - f1: 0.7597 - val_loss: 0.7507 - val_f1: 0.2500\n",
            "Epoch 296/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3467 - f1: 0.7721 - val_loss: 0.8020 - val_f1: 0.4722\n",
            "Epoch 297/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.2980 - f1: 0.8139 - val_loss: 0.7527 - val_f1: 0.4687\n",
            "Epoch 298/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.3096 - f1: 0.8079 - val_loss: 0.8224 - val_f1: 0.4919\n",
            "Epoch 299/300\n",
            "13/13 [==============================] - 3s 223ms/step - loss: 0.3163 - f1: 0.7923 - val_loss: 0.9351 - val_f1: 0.3929\n",
            "Epoch 300/300\n",
            "13/13 [==============================] - 3s 225ms/step - loss: 0.3011 - f1: 0.8256 - val_loss: 0.9546 - val_f1: 0.6774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREDICTING EVALUATION DATASET"
      ],
      "metadata": {
        "id": "cfeorDU1zIcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predIdxs = model.predict_generator(valid_gen)\n",
        "\n",
        "predIdxs = np.argmax(predIdxs, axis=1)\n",
        "\n",
        "predIdxs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY9Xt2RGrVx8",
        "outputId": "9ae64164-b6c0-424c-a410-a93fee884ef2"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 2, 1, 0, 0, 2, 1, 0, 2, 2, 0, 2, 1, 0, 0, 1, 1, 1, 2, 2, 1,\n",
              "       2, 0, 1, 1, 2, 0, 0, 1, 0, 2, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREDICTING TEST DATASET"
      ],
      "metadata": {
        "id": "CfL2zG6qtRA8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ylsGKgverV6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = test_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "\n",
        "predict = model.predict(test_generator,nb_samples)\n",
        "\n",
        "\n",
        "\n",
        "predIdxs = np.argmax(predict, axis=1)"
      ],
      "metadata": {
        "id": "DSVRZmR5ujLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc3dab8b-7210-42ac-8ecb-d32b501db789"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 2s 201ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results=pd.DataFrame({\"id\": filenames, \"target\": predIdxs})"
      ],
      "metadata": {
        "id": "Iz4RMOFqSbQS"
      },
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "glXDiDm3tBeS",
        "outputId": "f369eae6-7be6-4172-ed4d-cca98be27f8e"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id  target\n",
              "0    1001.png       1\n",
              "1    1445.png       1\n",
              "2    1530.png       2\n",
              "3       1.png       2\n",
              "4    1800.png       2\n",
              "..        ...     ...\n",
              "281  1878.png       2\n",
              "282  1294.png       2\n",
              "283  1276.png       2\n",
              "284  1117.png       1\n",
              "285  1192.png       2\n",
              "\n",
              "[286 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ad11cad-1899-41f6-9e28-716625a90471\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1001.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1445.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1530.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1800.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>1878.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>1294.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>1276.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>1117.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>1192.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>286 rows  2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ad11cad-1899-41f6-9e28-716625a90471')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8ad11cad-1899-41f6-9e28-716625a90471 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8ad11cad-1899-41f6-9e28-716625a90471');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#WE WILL JUST SEND THE TARGET\n",
        "\n",
        "results[\"target\"]"
      ],
      "metadata": {
        "id": "Uy6rx1ua2C-w",
        "outputId": "5212b4ef-bf4c-481c-a03c-8ca404dd8e87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      2\n",
              "3      2\n",
              "4      2\n",
              "      ..\n",
              "281    2\n",
              "282    2\n",
              "283    2\n",
              "284    1\n",
              "285    2\n",
              "Name: target, Length: 286, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results.to_csv(\"predictions.csv\") #EXPORTAMOS LOS RESULTADOS csv"
      ],
      "metadata": {
        "id": "AhED_o0rzYn4"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[\"target\"].to_json(\"predictions.json\") #EXPORTAMOS LOS RESULTADOS JSON"
      ],
      "metadata": {
        "id": "dRdPliW41PEW"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7e3Y429S1RU-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}